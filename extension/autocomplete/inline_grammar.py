import os
import argparse
from collections import defaultdict

parser = argparse.ArgumentParser(description='Inline the auto-complete PEG grammar files')
parser.add_argument(
    '--print', action='store_true', help='Print the grammar instead of writing to a file', default=False
)
parser.add_argument(
    '--grammar-file',
    action='store_true',
    help='Write the grammar to a .gram file instead of a C++ header',
    default=False,
)

args = parser.parse_args()

autocomplete_dir = 'extension/autocomplete'
statements_dir = os.path.join(autocomplete_dir, 'grammar', 'statements')
keywords_dir = os.path.join(autocomplete_dir, 'grammar', 'keywords')
target_file = os.path.join(autocomplete_dir, 'include', 'inlined_grammar.hpp')

contents = ""

# Maps filenames to string categories
FILENAME_TO_CATEGORY = {
    "reserved_keyword.list": "RESERVED_KEYWORD",
    "unreserved_keyword.list": "UNRESERVED_KEYWORD",
    "column_name_keyword.list": "COL_NAME_KEYWORD",
    "func_name_keyword.list": "TYPE_FUNC_NAME_KEYWORD",
    "type_name_keyword.list": "TYPE_FUNC_NAME_KEYWORD",
}

# Defines the C++ enum string and the integer value for each bitmask
# This is the single source of truth for the mapping
CPP_CATEGORY_MAP = {
    "RESERVED_KEYWORD": ("KeywordCategory::KEYWORD_RESERVED", 1 << 1),
    "UNRESERVED_KEYWORD": ("KeywordCategory::KEYWORD_UNRESERVED", 1 << 0),
    "TYPE_FUNC_NAME_KEYWORD": ("KeywordCategory::KEYWORD_TYPE_FUNC", 1 << 2),
    "COL_NAME_KEYWORD": ("KeywordCategory::KEYWORD_COL_NAME", 1 << 3),
}

# For validation during the loading phase
reserved_set = set()
unreserved_set = set()

# Final output dictionary: maps a keyword string to its integer bitmask
final_keyword_masks = defaultdict(int)


def load_keywords(filepath):
    with open(filepath, "r") as f:
        return [line.strip().lower() for line in f if line.strip()]


# Validate and aggregate keywords into the bitmask dictionary
for filename in os.listdir(keywords_dir):
    if filename not in FILENAME_TO_CATEGORY:
        continue

    category = FILENAME_TO_CATEGORY[filename]
    keywords = load_keywords(os.path.join(keywords_dir, filename))
    _, category_bitmask = CPP_CATEGORY_MAP[category]

    for kw in keywords:
        # --- Validation (largely the same as your original script) ---
        if category == "RESERVED_KEYWORD":
            if kw in reserved_set:
                print(f"Duplicate keyword '{kw}' in reserved keywords")
                exit(1)
            if final_keyword_masks[kw] != 0:  # Check if it has ANY other category
                print(f"Keyword '{kw}' is marked as both reserved and something else")
                exit(1)
            reserved_set.add(kw)
        elif category == "UNRESERVED_KEYWORD":
            if kw in unreserved_set:
                print(f"Duplicate keyword '{kw}' in unreserved keywords")
                exit(1)
            if kw in reserved_set:
                print(f"Keyword '{kw}' is marked as both reserved and unreserved")
                exit(1)
            unreserved_set.add(kw)
        elif category in ["COL_NAME_KEYWORD", "TYPE_FUNC_NAME_KEYWORD"]:
            if kw in reserved_set:
                print(f"Keyword '{kw}' is marked as both reserved and {category}")
                exit(1)
            if kw in unreserved_set:
                print(f"Keyword '{kw}' is marked as both unreserved and {category}")
                exit(1)

        # --- Aggregation using bitwise OR ---
        final_keyword_masks[kw] |= category_bitmask

# Generate C++ map file
output_path = os.path.join(autocomplete_dir, "keyword_map.cpp")
with open(output_path, "w") as f:
    f.write("/* THIS FILE WAS AUTOMATICALLY GENERATED BY inline_grammar.py */\n")
    f.write("#include \"keyword_helper.hpp\"\n\n")
    f.write("namespace duckdb {\n")
    f.write("void KeywordHelper::InitializeKeywordMap() {\n")
    f.write("    if (initialized) return;\n")
    f.write("    initialized = true;\n")

    # Sort keywords for deterministic output
    for kw in sorted(final_keyword_masks.keys()):
        mask = final_keyword_masks[kw]

        # Build the C++ expression from the final bitmask
        cpp_parts = []
        for category_name, (cpp_string, bit) in CPP_CATEGORY_MAP.items():
            if mask & bit:
                cpp_parts.append(cpp_string)

        # Join parts with a bitwise OR, or use NONE if empty
        cpp_expression = " | ".join(cpp_parts) if cpp_parts else "KeywordCategory::KEYWORD_NONE"

        f.write(f'    keyword_map["{kw}"] = {cpp_expression};\n')

    f.write("}\n")
    f.write("}\n")

print(f"Successfully generated {output_path}")


def filename_to_upper_camel(file):
    name, _ = os.path.splitext(file)  # column_name_keywords
    parts = name.split('_')  # ['column', 'name', 'keywords']
    return ''.join(p.capitalize() for p in parts)


for file in os.listdir(keywords_dir):
    if not file.endswith('.list'):
        continue
    rule_name = filename_to_upper_camel(file)
    rule = f"{rule_name} <- "
    with open(os.path.join(keywords_dir, file), 'r') as f:
        lines = [f"'{line.strip()}'i" for line in f if line.strip()]
        rule += " /\n".join(lines) + "\n"
    contents += rule

for file in os.listdir(statements_dir):
    if not file.endswith('.gram'):
        raise Exception(f"File {file} does not end with .gram")
    with open(os.path.join(statements_dir, file), 'r') as f:
        contents += f.read() + "\n"

if args.print:
    print(contents)
    exit(0)

if args.grammar_file:
    grammar_file = target_file.replace('.hpp', '.gram')
    with open(grammar_file, 'w+') as f:
        f.write(contents)
    exit(0)


def get_grammar_bytes(contents, add_null_terminator=True):
    result_text = ""
    for line in contents.split('\n'):
        if len(line) == 0:
            continue
        result_text += "\t\"" + line.replace('\\', '\\\\').replace('"', '\\"') + "\\n\"\n"
    return result_text


with open(target_file, 'w+') as f:
    f.write(
        '''/* THIS FILE WAS AUTOMATICALLY GENERATED BY inline_grammar.py */

namespace duckdb {

const char INLINED_PEG_GRAMMAR[] = {
'''
        + get_grammar_bytes(contents)
        + '''
};

} // namespace duckdb
'''
    )
